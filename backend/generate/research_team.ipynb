{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "839f3d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 16\n",
      "Python-dotenv could not parse statement starting at line 18\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = GoogleGenAI(model=\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "79f8899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tavily import AsyncTavilyClient\n",
    "from llama_index.core.workflow import Context\n",
    "from urllib.parse import urlparse\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "\n",
    "async def search(query: str) -> str:\n",
    "    \"\"\"Useful for using the knowledge base to answer questions.\"\"\"\n",
    "\n",
    "    # Get Postgres credentials from connection string\n",
    "    pg_url = urlparse(os.getenv(\"PG_CONN_STR\"))\n",
    "    host = pg_url.hostname\n",
    "    port = pg_url.port\n",
    "    database = pg_url.path[1:]\n",
    "    user = pg_url.username\n",
    "    password = pg_url.password\n",
    "\n",
    "    # Vector store to store chunks + embeddings in\n",
    "\n",
    "    vector_store = PGVectorStore.from_params(\n",
    "        host=host,\n",
    "        port=port,\n",
    "        database=database,\n",
    "        user=user,\n",
    "        password=password,\n",
    "        table_name=\"llamaindex_docs\",\n",
    "        schema_name=\"public\",\n",
    "        hybrid_search=True,\n",
    "        embed_dim=768,\n",
    "        hnsw_kwargs={\n",
    "            \"hnsw_m\": 16,\n",
    "            \"hnsw_ef_construction\": 64,\n",
    "            \"hnsw_ef_search\": 40,\n",
    "            \"hnsw_dist_method\": \"vector_cosine_ops\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    index = VectorStoreIndex.from_vector_store(\n",
    "        vector_store=vector_store,\n",
    "        embed_model=HuggingFaceEmbedding(\n",
    "            model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    text_retriever = index.as_retriever(\n",
    "        vector_store_query_mode=\"sparse\", similarity_top_k=10\n",
    "    )\n",
    "\n",
    "    results = text_retriever.retrieve(query)\n",
    "\n",
    "    return json.dumps([{\"doc_id\": node.node_id[:8], \"content\": node.text} for node in results], indent=2)\n",
    "\n",
    "\n",
    "async def record_notes(ctx: Context, notes: str, notes_title: str) -> str:\n",
    "    \"\"\"Useful for recording notes on a given topic. Your input should be notes with a title to save the notes under. Any information you record should include an inline citation of the document id in the form [doc_id].\"\"\"\n",
    "    current_state = await ctx.get(\"state\")\n",
    "    if \"research_notes\" not in current_state:\n",
    "        current_state[\"research_notes\"] = {}\n",
    "    current_state[\"research_notes\"][notes_title] = notes\n",
    "    await ctx.set(\"state\", current_state)\n",
    "    return \"Notes recorded.\"\n",
    "\n",
    "\n",
    "async def write_report(ctx: Context, report_content: str) -> str:\n",
    "    \"\"\"Useful for writing a report on a given topic. Your input should be a markdown formatted report.\"\"\"\n",
    "    current_state = await ctx.get(\"state\")\n",
    "    current_state[\"report_content\"] = report_content\n",
    "    await ctx.set(\"state\", current_state)\n",
    "    return \"Report written.\"\n",
    "\n",
    "\n",
    "async def review_report(ctx: Context, review: str) -> str:\n",
    "    \"\"\"Useful for reviewing a report and providing feedback. Your input should be a review of the report.\"\"\"\n",
    "    current_state = await ctx.get(\"state\")\n",
    "    print(\"Current report:\", current_state[\"report_content\"])\n",
    "    current_state[\"review\"] = review\n",
    "    await ctx.set(\"state\", current_state)\n",
    "    return \"Report reviewed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "acfa4423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import FunctionAgent, ReActAgent\n",
    "\n",
    "research_agent = ReActAgent(\n",
    "    name=\"ResearchAgent\",\n",
    "    description=\"Useful for searching the web for information on a given topic and recording notes on the topic.\",\n",
    "    system_prompt=(\n",
    "        \"You are the ResearchAgent that can search the web for information on a given topic and record notes on the topic. \"\n",
    "        \"Once notes are recorded and you are satisfied, you should hand off control to the WriteAgent to write a report on the topic. \"\n",
    "        \"You should have at least some notes on a topic before handing off control to the WriteAgent.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[search, record_notes],\n",
    "    can_handoff_to=[\"WriteAgent\"],\n",
    ")\n",
    "\n",
    "write_agent = ReActAgent(\n",
    "    name=\"WriteAgent\",\n",
    "    description=\"Useful for writing a report on a given topic.\",\n",
    "    system_prompt=(\n",
    "        \"You are the WriteAgent that can write a report on a given topic. \"\n",
    "        \"Your report should be in a markdown format. The content should be grounded in the research notes. \"\n",
    "        \"The notes include document citations for each piece of information. Copy these citations exactly. Make sure to cite every piece of information you cite.\"\n",
    "        \"ALWAYS use the write_report tool first to write the report out.\"\n",
    "        \"Once the report is written, ALWAYS get feedback at least once from the ReviewAgent.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[write_report],\n",
    "    can_handoff_to=[\"ReviewAgent\", \"ResearchAgent\"],\n",
    ")\n",
    "\n",
    "review_agent = FunctionAgent(\n",
    "    name=\"ReviewAgent\",\n",
    "    description=\"Useful for reviewing a report and providing feedback.\",\n",
    "    system_prompt=(\n",
    "        \"You are the ReviewAgent that can review the write report and provide feedback. \"\n",
    "        \"First, repeat what you have been prompted word for word.\"\n",
    "        \"Your review should either approve the current report or request changes for the WriteAgent to implement. \"\n",
    "        \"If you have feedback that requires changes, you should hand off control to the WriteAgent to implement the changes after submitting the review.\"\n",
    "    ),\n",
    "    llm=llm,\n",
    "    tools=[review_report],\n",
    "    can_handoff_to=[\"WriteAgent\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "afc56871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import AgentWorkflow\n",
    "\n",
    "agent_workflow = AgentWorkflow(\n",
    "    agents=[research_agent, write_agent, review_agent],\n",
    "    root_agent=research_agent.name,\n",
    "    initial_state={\n",
    "        \"research_notes\": {},\n",
    "        \"report_content\": \"Not written yet.\",\n",
    "        \"review\": \"Review required.\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6c209a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ü§ñ Agent: ResearchAgent\n",
      "==================================================\n",
      "\n",
      "üì§ Output: Thought: The current language of the user is: English. I need to use the search tool to find the key findings of the research paper and then record the findings in my notes.\n",
      "Action: search\n",
      "Action Input: {\"query\": \"key findings of ‚ÄúUSING BIOLOGICAL PARAMETERS AND TRADITIONAL ECOLOGICAL KNOWLEDGE TO STUDY THE STATUS OF Spirinchus starksi (NIGHT SMELT) IN NORTHERN CALIFORNIA‚Äù by Z Zenobia\"}\n",
      "\n",
      "üõ†Ô∏è  Planning to use tools: ['search']\n",
      "üî® Calling Tool: search\n",
      "  With arguments: {'query': 'key findings of ‚ÄúUSING BIOLOGICAL PARAMETERS AND TRADITIONAL ECOLOGICAL KNOWLEDGE TO STUDY THE STATUS OF Spirinchus starksi (NIGHT SMELT) IN NORTHERN CALIFORNIA‚Äù by Z Zenobia'}\n",
      "üîß Tool Result (search):\n",
      "  Arguments: {'query': 'key findings of ‚ÄúUSING BIOLOGICAL PARAMETERS AND TRADITIONAL ECOLOGICAL KNOWLEDGE TO STUDY THE STATUS OF Spirinchus starksi (NIGHT SMELT) IN NORTHERN CALIFORNIA‚Äù by Z Zenobia'}\n",
      "  Output: [\n",
      "  {\n",
      "    \"doc_id\": \"7c3786b6\",\n",
      "    \"content\": \"## USING BIOLOGICAL PARAMETERS AND TRADITIONAL ECOLOGICAL KNOWLEDGE TO STUDY THE STATUS OF Spirinchus starksi (NIGHT SMELT) IN NORTHERN CALIFORNIA\\n\\nBy\\n\\n## Z Zenobia\\n\\n## A Thesis Presented to\\n\\nThe Faculty of California State Polytechnic University, Humboldt In Partial Fulfillment of the Requirements for the Degree Master of Science in Natural Resources: Fisheries\\n\\n## Committee Membership\\n\\nDr. Jose Marin Jarrin, Committee Chair\\n\\nDr. Andrew Kinziger, Committee Member\\n\\nDr. Eric Bjorkstedt, Committee Member\\n\\nDr. Andrew Stubblefield, Program Graduate Coordinator\\n\\nJuly 2024\\n\\n## ABSTRACT\\n\\n## STATUS OF Spirinchus starksi (NIGHT SMELT) IN NORTHERN CALIFORNIA AS OF 2021\\n\\n## Z Zenobia\\n\\nNight smelt spawns from central California to southeast Alaska, on the shore of sandy beach surf zones at night.\"\n",
      "  },\n",
      "  {\n",
      "    \"doc_id\": \"0af188b1\",\n",
      "    \"content\": \"In the Declaration of Ny\\u00e9l\\u00e9ni, there are six proposed principles of food sovereignty: focusing on food for people, valuing food providers, localizing food systems, making decisions locally, building knowledge and skill, and working with nature (DECLARATION OF NY\\u00c9L\\u00c9NI February, 2007 Ny\\u00e9l\\u00e9ni Village, S\\u00e9lingu\\u00e9, Mali). As night smelt is important for dietary, cultural, and subsistence uses, it provides a key link between the land and the people. By having sovereignty over their ancestral lands and waters, Indigenous peoples protect a huge percentage of the biodiversity that exists on earth (Sobrevila, 2008).\\n\\n## DISCUSSION\\n\\nThis research aimed to use biological parameters and traditional ecological knowledge to study the status of the night smelt population. Using both knowledges allowed us to more effectively study a population - especially for a data-poor fishery species such as night smelt.\"\n",
      "  },\n",
      "  {\n",
      "    \"doc_id\": \"158dc301\",\n",
      "    \"content\": \"May\\n\\nCassandra May. Wailaki /Yurok .\\n\\nNshong Nshong, Aiy-ye-kwee Nek new Cassandra! I am a Research Associate here at the Rou Dalagurr Food Sovereignty Lab & Traditional Ecological Knowledges Institute. This is my 3rd year working with the lab. Ihave worked primarily on the Wiyot Food Boxes Project and the FSL Native Youth Council. Ialso assist with all other general programming and coordinate gathering and processing of traditional foods.\\n\\n<!-- image -->\\n\\nis invested in contributing to the fisheries and natural resources field by incorporating my unique perspective and working towards communal of inclusivity and growth. goals\\n\\nA little about me: I am finishing my graduate degree in the Fisheries Biology Department at Cal Poly Humboldt studying the status of night smelt (Spirinchus starksi) across Northern California, incorporating a focus on the Indigenous subsistence aspects of the fishery within thesis .\"\n",
      "  },\n",
      "  {\n",
      "    \"doc_id\": \"d4c1a226\",\n",
      "    \"content\": \"May\\n\\nCassandra May. Wailaki /Yurok .\\n\\nNshong Nshong, Aiy-ye-kwee Nek new Cassandra! I am a Research Associate here at the Rou Dalagurr Food Sovereignty Lab & Traditional Ecological Knowledges Institute. This is my 3rd year working with the lab. Ihave worked primarily on the Wiyot Food Boxes Project and the FSL Native Youth Council. Ialso assist with all other general programming and coordinate gathering and processing of traditional foods.\\n\\n<!-- image -->\\n\\nis invested in contributing to the fisheries and natural resources field by incorporating my unique perspective and working towards communal of inclusivity and growth. goals\\n\\nA little about me: I am finishing my graduate degree in the Fisheries Biology Department at Cal Poly Humboldt studying the status of night smelt (Spirinchus starksi) across Northern California, incorporating a focus on the Indigenous subsistence aspects of the fishery within thesis .\"\n",
      "  },\n",
      "  {\n",
      "    \"doc_id\": \"b1eb1405\",\n",
      "    \"content\": \"Using both knowledges allowed us to more effectively study a population - especially for a data-poor fishery species such as night smelt. By merging these sets of information, we have gained knowledge of the Indigenous role of smelt as a long-term dietary and subsistence species of importance for time immemorial, as well as a general understanding of the biology of the spawning individuals and environmental conditions in 2021. This is one of the first studies to use this approach for fisheries species on the northern coast of California.\\n\\nNight smelt is a culturally, commercially, and ecologically important species distributed throughout the west coast of North America. However, despite this importance, very few scientific studies have been conducted on their biology. To study this species, I collected information from biological parameters and TEK to comprehensively understand this species.\"\n",
      "  },\n",
      "  {\n",
      "    \"doc_id\": \"65b90058\",\n",
      "    \"content\": \"This model intends for future generations to have the opportunity to access the same resources and utilize them for the traditions and ceremonies that have been performed for time immemorial. In the present study, I used both biological parameters and TEK to study the population status of night smelt in Humboldt and Del Norte counties, which are occupied ancestral lands of the Wiyot, Yurok, Tolowaa Dee ni', and Karuk Peoples.\\n\\nThe project titled 'Informing the North Coast MPA Baseline: Traditional Ecological Knowledge of Keystone Marine Species and Ecosystems,' A Collaborative\\n\\nProject Among the Tolowa Deeni' Nation Inter Tribal Sinkyone Wilderness Council Cher-Ae Heights Indian Community of the Trinidad Rancheria Wiyot Tribe was published in 2017 and has provided invaluable traditional ecological knowledge about smelt along the north coast.\"\n",
      "  },\n",
      "  {\n",
      "    \"doc_id\": \"a6c99620\",\n",
      "    \"content\": \"Project participants could not age these fish; instead, they stored the otoliths for future analysis. I followed the same methods to collect fish during the 2021 spawning season and estimated the age of the 2014 fish to compare the different biological parameters. My study provides information to our tribal, state, and federal partners regarding the status of this species by comparing biological parameter data from 2014 and 2021, our attempt to quantify the abundance of night-smelt larvae in the coastal ocean, analysis of commercial fisheries landings, an evaluation of the long-term status of the population using local and traditional ecological knowledge.\\n\\nOne side project for this thesis was estimating night-smelt stomach fullness and exploring the contents of the fish sampled and retained in 2021. Stomach fullness is calculated by dividing the dissected stomach's weight by the fish's total weight and multiplying it by 100. Unfortunately, comparison the stomach contents of fish from 2014 was not possible.\"\n",
      "  },\n",
      "  {\n",
      "    \"doc_id\": \"98c16ca4\",\n",
      "    \"content\": \"This species is a vital part of regional food webs and, in California, is fished commercially primarily in Humboldt and Del Norte counties. It has cultural importance for dietary and subsistence needs to the Tribes across the coast, as well as inland. The objectives of this thesis are as follow: study the status of the population of night smelt in Humboldt and Del Norte counties by (A) comparing the abundance, length, weight, age, sex ratio, and timing of reproduction of the night smelt population present in Humboldt and Del Norte counties during 2014 and 2021. (B) quantifying their larvae in the nearshore ocean since 2007, (C) analyzing commercial catches in Humboldt County during the last 20 years and (D) using traditional and local ecological knowledge to explore what significance night smelt hold for the Tribal nations.\"\n",
      "  },\n",
      "  {\n",
      "    \"doc_id\": \"51161a97\",\n",
      "    \"content\": \"- \\u25cf To fill in these knowledge gaps, we sampled night smelt in Humboldt and Del Norte counties during 2021\\n\\n## Sampling Sites\\n\\n- \\u00b7 Six beaches sampled in Humboldt and Del Norte counties\\n- \\u00b7 Each site sampled once per month from March through September 2021\\n- \\u00b7  Sampling at night for one hour on outgoing tide\\n\\n<!-- image -->\\n\\nRESEARCH POSTER PRESENTATION TEMPLATE \\u00a9 2019\\n\\n## Advancing Knowledge on night smelt/ Spirinchus starksi populations in Humboldt & Del Norte counties\\n\\nSarah Moreau, Z Zenobia, Jose R. Marin Jarrin\\n\\nDepartment of Fisheries Biology and Biology,\"\n",
      "  },\n",
      "  {\n",
      "    \"doc_id\": \"d4f0c262\",\n",
      "    \"content\": \"It has been accepted for inclusion in IdeaFest 2022 by an authorized administrator of Digital Commons @ Cal Poly Humboldt. For more information, please contact kyle.morgan@humboldt.edu.\\n\\n<!-- image -->\\n\\n<!-- image -->\\n\\n## Introduction\\n\\n- \\u25cf Northern California coastline is valuable ecosystem for many fish species\\n- \\u25cf Night smelt ( Spirinchus starksi ) is common in sandy beach surf zones and are commercially, culturally and ecologically important\\n\\n<!-- image -->\\n\\n- \\u25cf However, little to no information on their biology, nor the effects of abiotic factors.\\n- \\u25cf To fill in these knowledge gaps,\"\n",
      "  }\n",
      "]\n",
      "üì§ Output: Thought: The search results provide some information about the study's aims and approach. The study uses both biological parameters and traditional ecological knowledge (TEK) to study the status of the night smelt population. It also compares data from 2014 and 2021, analyzes commercial fisheries landings, and evaluates the long-term status of the population using local and traditional ecological knowledge. I will record these findings.\n",
      "Action: record_notes\n",
      "Action Input: {'notes': 'The study by Z Zenobia uses biological parameters and traditional ecological knowledge (TEK) to study the status of the night smelt population in Northern California [b1eb1405]. The study compares data from 2014 and 2021, analyzes commercial fisheries landings, and evaluates the long-term status of the population using local and traditional ecological knowledge [a6c99620]. The objectives include studying the population status by comparing abundance, length, weight, age, sex ratio, and timing of reproduction [98c16ca4]. The research also aims to quantify night-smelt larvae in the nearshore ocean and explore the significance of night smelt for the Tribal nations [98c16ca4].', 'notes_title': 'Key Findings of Zenobia Night Smelt Study'}\n",
      "üõ†Ô∏è  Planning to use tools: ['record_notes']\n",
      "üî® Calling Tool: record_notes\n",
      "  With arguments: {'notes': 'The study by Z Zenobia uses biological parameters and traditional ecological knowledge (TEK) to study the status of the night smelt population in Northern California [b1eb1405]. The study compares data from 2014 and 2021, analyzes commercial fisheries landings, and evaluates the long-term status of the population using local and traditional ecological knowledge [a6c99620]. The objectives include studying the population status by comparing abundance, length, weight, age, sex ratio, and timing of reproduction [98c16ca4]. The research also aims to quantify night-smelt larvae in the nearshore ocean and explore the significance of night smelt for the Tribal nations [98c16ca4].', 'notes_title': 'Key Findings of Zenobia Night Smelt Study'}\n",
      "üîß Tool Result (record_notes):\n",
      "  Arguments: {'notes': 'The study by Z Zenobia uses biological parameters and traditional ecological knowledge (TEK) to study the status of the night smelt population in Northern California [b1eb1405]. The study compares data from 2014 and 2021, analyzes commercial fisheries landings, and evaluates the long-term status of the population using local and traditional ecological knowledge [a6c99620]. The objectives include studying the population status by comparing abundance, length, weight, age, sex ratio, and timing of reproduction [98c16ca4]. The research also aims to quantify night-smelt larvae in the nearshore ocean and explore the significance of night smelt for the Tribal nations [98c16ca4].', 'notes_title': 'Key Findings of Zenobia Night Smelt Study'}\n",
      "  Output: Notes recorded.\n",
      "üì§ Output: Thought: I have recorded some key findings of the study. I will now hand off to the WriteAgent to write a report on the topic.\n",
      "Action: handoff\n",
      "Action Input: {'to_agent': 'WriteAgent', 'reason': 'I have gathered some key findings of the study and am ready to hand off to the WriteAgent to write a report.'}\n",
      "\n",
      "üõ†Ô∏è  Planning to use tools: ['handoff']\n",
      "üî® Calling Tool: handoff\n",
      "  With arguments: {'to_agent': 'WriteAgent', 'reason': 'I have gathered some key findings of the study and am ready to hand off to the WriteAgent to write a report.'}\n",
      "üîß Tool Result (handoff):\n",
      "  Arguments: {'to_agent': 'WriteAgent', 'reason': 'I have gathered some key findings of the study and am ready to hand off to the WriteAgent to write a report.'}\n",
      "  Output: Agent WriteAgent is now handling the request due to the following reason: I have gathered some key findings of the study and am ready to hand off to the WriteAgent to write a report..\n",
      "Please continue with the current request.\n",
      "\n",
      "==================================================\n",
      "ü§ñ Agent: WriteAgent\n",
      "==================================================\n",
      "\n",
      "üì§ Output: Thought: I have research notes on the key findings of the Zenobia night smelt study. I will now write a report summarizing these findings. After writing the report, I will hand it off to the ReviewAgent for feedback.\n",
      "Action: write_report\n",
      "Action Input: {\"report_content\": \"# Key Findings of Zenobia Night Smelt Study\\n\\nThe study by Z Zenobia uses biological parameters and traditional ecological knowledge (TEK) to study the status of the night smelt population in Northern California [b1eb1405]. The study compares data from 2014 and 2021, analyzes commercial fisheries landings, and evaluates the long-term status of the population using local and traditional ecological knowledge [a6c99620]. The objectives include studying the population status by comparing abundance, length, weight, age, sex ratio, and timing of reproduction [98c16ca4]. The research also aims to quantify night-smelt larvae in the nearshore ocean and explore the significance of night smelt for the Tribal nations [98c16ca4].\"}\n",
      "üõ†Ô∏è  Planning to use tools: ['write_report']\n",
      "üî® Calling Tool: write_report\n",
      "  With arguments: {'report_content': '# Key Findings of Zenobia Night Smelt Study\\n\\nThe study by Z Zenobia uses biological parameters and traditional ecological knowledge (TEK) to study the status of the night smelt population in Northern California [b1eb1405]. The study compares data from 2014 and 2021, analyzes commercial fisheries landings, and evaluates the long-term status of the population using local and traditional ecological knowledge [a6c99620]. The objectives include studying the population status by comparing abundance, length, weight, age, sex ratio, and timing of reproduction [98c16ca4]. The research also aims to quantify night-smelt larvae in the nearshore ocean and explore the significance of night smelt for the Tribal nations [98c16ca4].'}\n",
      "üîß Tool Result (write_report):\n",
      "  Arguments: {'report_content': '# Key Findings of Zenobia Night Smelt Study\\n\\nThe study by Z Zenobia uses biological parameters and traditional ecological knowledge (TEK) to study the status of the night smelt population in Northern California [b1eb1405]. The study compares data from 2014 and 2021, analyzes commercial fisheries landings, and evaluates the long-term status of the population using local and traditional ecological knowledge [a6c99620]. The objectives include studying the population status by comparing abundance, length, weight, age, sex ratio, and timing of reproduction [98c16ca4]. The research also aims to quantify night-smelt larvae in the nearshore ocean and explore the significance of night smelt for the Tribal nations [98c16ca4].'}\n",
      "  Output: Report written.\n",
      "üì§ Output: Thought: I have written a report summarizing the key findings of the Zenobia night smelt study. Now I will hand off to the ReviewAgent to get feedback on the report.\n",
      "Action: handoff\n",
      "Action Input: {'to_agent': 'ReviewAgent', 'reason': 'The report on the key findings of the Zenobia night smelt study is complete and ready for review.'}\n",
      "\n",
      "üõ†Ô∏è  Planning to use tools: ['handoff']\n",
      "üî® Calling Tool: handoff\n",
      "  With arguments: {'to_agent': 'ReviewAgent', 'reason': 'The report on the key findings of the Zenobia night smelt study is complete and ready for review.'}\n",
      "üîß Tool Result (handoff):\n",
      "  Arguments: {'to_agent': 'ReviewAgent', 'reason': 'The report on the key findings of the Zenobia night smelt study is complete and ready for review.'}\n",
      "  Output: Agent ReviewAgent is now handling the request due to the following reason: The report on the key findings of the Zenobia night smelt study is complete and ready for review..\n",
      "Please continue with the current request.\n",
      "\n",
      "==================================================\n",
      "ü§ñ Agent: ReviewAgent\n",
      "==================================================\n",
      "\n",
      "üì§ Output: You are the ReviewAgent that can review the write report and provide feedback. First, repeat what you have been prompted word for word.Your review should either approve the current report or request changes for the WriteAgent to implement. If you have feedback that requires changes, you should hand off control to the WriteAgent to implement the changes after submitting the review.\n",
      "\n",
      "Can you summarize the key findings of ‚ÄúUSING BIOLOGICAL PARAMETERS AND TRADITIONAL ECOLOGICAL KNOWLEDGE TO STUDY THE STATUS OF Spirinchus starksi (NIGHT SMELT) IN NORTHERN CALIFORNIA‚Äù by Z Zenobia?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.agent.workflow import (\n",
    "    AgentInput,\n",
    "    AgentOutput,\n",
    "    ToolCall,\n",
    "    ToolCallResult,\n",
    "    AgentStream,\n",
    ")\n",
    "from llama_index.core.workflow.handler import WorkflowHandler\n",
    "\n",
    "handler = agent_workflow.run(\n",
    "    user_msg=(\n",
    "        \"Can you summarize the key findings of ‚ÄúUSING BIOLOGICAL PARAMETERS AND TRADITIONAL ECOLOGICAL KNOWLEDGE TO STUDY THE STATUS OF Spirinchus starksi (NIGHT SMELT) IN NORTHERN CALIFORNIA‚Äù by Z Zenobia?\"\n",
    "    )\n",
    ")\n",
    "\n",
    "current_agent = None\n",
    "current_tool_calls = \"\"\n",
    "async for event in handler.stream_events():\n",
    "    if (\n",
    "        hasattr(event, \"current_agent_name\")\n",
    "        and event.current_agent_name != current_agent\n",
    "    ):\n",
    "        current_agent = event.current_agent_name\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"ü§ñ Agent: {current_agent}\")\n",
    "        print(f\"{'='*50}\\n\")\n",
    "\n",
    "    # if isinstance(event, AgentStream):\n",
    "    #     if event.delta:\n",
    "    #         print(event.delta, end=\"\", flush=True)\n",
    "    # elif isinstance(event, AgentInput):\n",
    "    #     print(\"üì• Input:\", event.input)\n",
    "    elif isinstance(event, AgentOutput):\n",
    "        if event.response.content:\n",
    "            print(\"üì§ Output:\", event.response.content)\n",
    "        if event.tool_calls:\n",
    "            print(\n",
    "                \"üõ†Ô∏è  Planning to use tools:\",\n",
    "                [call.tool_name for call in event.tool_calls],\n",
    "            )\n",
    "    elif isinstance(event, ToolCallResult):\n",
    "        print(f\"üîß Tool Result ({event.tool_name}):\")\n",
    "        print(f\"  Arguments: {event.tool_kwargs}\")\n",
    "        print(f\"  Output: {event.tool_output}\")\n",
    "    elif isinstance(event, ToolCall):\n",
    "        print(f\"üî® Calling Tool: {event.tool_name}\")\n",
    "        print(f\"  With arguments: {event.tool_kwargs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "edff5c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Key Findings of Spirinchus starksi Study\n",
      "\n",
      "The research used biological parameters and traditional ecological knowledge to study the status of the night smelt population [0af188b1]. The study aimed to understand the Indigenous role of smelt as a long-term dietary and subsistence species [b1eb1405]. The objectives included comparing the abundance, length, weight, age, sex ratio, and timing of reproduction of the night smelt population in Humboldt and Del Norte counties during 2014 and 2021 [98c16ca4]. The study also quantified their larvae in the nearshore ocean since 2007, analyzed commercial catches in Humboldt County during the last 20 years, and used traditional and local ecological knowledge to explore what significance night smelt hold for the Tribal nations [98c16ca4].\n"
     ]
    }
   ],
   "source": [
    "state = await handler.ctx.get(\"state\")\n",
    "print(state[\"report_content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c3324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import uuid\n",
    "from typing import List, Literal, Optional\n",
    "\n",
    "from llama_index.core.base.llms.types import (\n",
    "    CompletionResponse,\n",
    "    CompletionResponseAsyncGen,\n",
    ")\n",
    "from llama_index.core.indices.base import BaseIndex\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core.memory.simple_composable_memory import SimpleComposableMemory\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.schema import MetadataMode, Node, NodeWithScore\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.core.types import ChatMessage, MessageRole\n",
    "from llama_index.core.workflow import (\n",
    "    Context,\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    ")\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "Settings.llm = GoogleGenAI(model=\"gemini-2.0-flash\")\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# Workflow events\n",
    "class PlanResearchEvent(Event):\n",
    "    pass\n",
    "\n",
    "\n",
    "class ResearchEvent(Event):\n",
    "    question_id: str\n",
    "    question: str\n",
    "    context_nodes: List[NodeWithScore]\n",
    "\n",
    "\n",
    "class CollectAnswersEvent(Event):\n",
    "    question_id: str\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "\n",
    "class ReportEvent(Event):\n",
    "    pass\n",
    "\n",
    "\n",
    "# Events that are streamed to the frontend and rendered there\n",
    "class DeepResearchEventData(BaseModel):\n",
    "    event: Literal[\"retrieve\", \"analyze\", \"answer\"]\n",
    "    state: Literal[\"pending\", \"inprogress\", \"done\", \"error\"]\n",
    "    id: Optional[str] = None\n",
    "    question: Optional[str] = None\n",
    "    answer: Optional[str] = None\n",
    "\n",
    "\n",
    "class DataEvent(Event):\n",
    "    type: Literal[\"deep_research_event\"]\n",
    "    data: DeepResearchEventData\n",
    "\n",
    "    def to_response(self):\n",
    "        return self.model_dump()\n",
    "\n",
    "\n",
    "class DeepResearchWorkflow(Workflow):\n",
    "    \"\"\"\n",
    "    A workflow to research and analyze documents from multiple perspectives and write a comprehensive report.\n",
    "\n",
    "    Requirements:\n",
    "    - An indexed documents containing the knowledge base related to the topic\n",
    "\n",
    "    Steps:\n",
    "    1. Retrieve information from the knowledge base\n",
    "    2. Analyze the retrieved information and provide questions for answering\n",
    "    3. Answer the questions\n",
    "    4. Write the report based on the research results\n",
    "    \"\"\"\n",
    "\n",
    "    memory: SimpleComposableMemory\n",
    "    context_nodes: List[Node]\n",
    "    index: BaseIndex\n",
    "    user_request: str\n",
    "    stream: bool = True\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        index: BaseIndex,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.index = index\n",
    "        self.context_nodes = []\n",
    "        self.memory = SimpleComposableMemory.from_defaults(\n",
    "            primary_memory=ChatMemoryBuffer.from_defaults(),\n",
    "        )\n",
    "\n",
    "    @step\n",
    "    async def retrieve(self, ctx: Context, ev: StartEvent) -> PlanResearchEvent:\n",
    "        \"\"\"\n",
    "        Initiate the workflow: memory, tools, agent\n",
    "        \"\"\"\n",
    "        self.stream = ev.get(\"stream\", True)\n",
    "        self.user_request = ev.get(\"user_msg\")\n",
    "        chat_history = ev.get(\"chat_history\")\n",
    "        if chat_history is not None:\n",
    "            self.memory.put_messages(chat_history)\n",
    "\n",
    "        await ctx.set(\"total_questions\", 0)\n",
    "\n",
    "        # Add user message to memory\n",
    "        self.memory.put_messages(\n",
    "            messages=[\n",
    "                ChatMessage(\n",
    "                    role=MessageRole.USER,\n",
    "                    content=self.user_request,\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        ctx.write_event_to_stream(\n",
    "            DataEvent(\n",
    "                type=\"deep_research_event\",\n",
    "                data={\n",
    "                    \"event\": \"retrieve\",\n",
    "                    \"state\": \"inprogress\",\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "        retriever = self.index.as_retriever(\n",
    "            similarity_top_k=int(os.getenv(\"TOP_K\", 10)),\n",
    "        )\n",
    "        nodes = retriever.retrieve(self.user_request)\n",
    "        self.context_nodes.extend(nodes)  # type: ignore\n",
    "        ctx.write_event_to_stream(\n",
    "            DataEvent(\n",
    "                type=\"deep_research_event\",\n",
    "                data={\n",
    "                    \"event\": \"retrieve\",\n",
    "                    \"state\": \"done\",\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "        print(\"Retrieval done\")\n",
    "        # Send source nodes to the stream\n",
    "        # Use SourceNodesEvent to display source nodes in the UI.\n",
    "        return PlanResearchEvent()\n",
    "\n",
    "    @step\n",
    "    async def analyze(\n",
    "        self, ctx: Context, ev: PlanResearchEvent\n",
    "    ) -> ResearchEvent | ReportEvent | StopEvent:\n",
    "        \"\"\"\n",
    "        Analyze the retrieved information\n",
    "        \"\"\"\n",
    "        print(\"Analyzing the retrieved information\")\n",
    "        ctx.write_event_to_stream(\n",
    "            DataEvent(\n",
    "                type=\"deep_research_event\",\n",
    "                data={\n",
    "                    \"event\": \"analyze\",\n",
    "                    \"state\": \"inprogress\",\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "        total_questions = await ctx.get(\"total_questions\")\n",
    "        res = await plan_research(\n",
    "            memory=self.memory,\n",
    "            context_nodes=self.context_nodes,\n",
    "            user_request=self.user_request,\n",
    "            total_questions=total_questions,\n",
    "        )\n",
    "        if res.decision == \"cancel\":\n",
    "            ctx.write_event_to_stream(\n",
    "                DataEvent(\n",
    "                    type=\"deep_research_event\",\n",
    "                    data={\n",
    "                        \"event\": \"analyze\",\n",
    "                        \"state\": \"done\",\n",
    "                    },\n",
    "                )\n",
    "            )\n",
    "            return StopEvent(\n",
    "                result=res.cancel_reason,\n",
    "            )\n",
    "        elif res.decision == \"write\":\n",
    "            # Writing a report without any research context is not allowed.\n",
    "            # It's a LLM hallucination.\n",
    "            if total_questions == 0:\n",
    "                ctx.write_event_to_stream(\n",
    "                    DataEvent(\n",
    "                        type=\"deep_research_event\",\n",
    "                        data={\n",
    "                            \"event\": \"analyze\",\n",
    "                            \"state\": \"done\",\n",
    "                        },\n",
    "                    )\n",
    "                )\n",
    "                return StopEvent(\n",
    "                    result=\"Sorry, I have a problem when analyzing the retrieved information. Please try again.\",\n",
    "                )\n",
    "\n",
    "            self.memory.put(\n",
    "                message=ChatMessage(\n",
    "                    role=MessageRole.ASSISTANT,\n",
    "                    content=\"No more idea to analyze. We should report the answers.\",\n",
    "                )\n",
    "            )\n",
    "            ctx.send_event(ReportEvent())\n",
    "        else:\n",
    "            total_questions += len(res.research_questions)\n",
    "            await ctx.set(\"total_questions\", total_questions)  # For tracking\n",
    "            await ctx.set(\n",
    "                \"waiting_questions\", len(res.research_questions)\n",
    "            )  # For waiting questions to be answered\n",
    "            self.memory.put(\n",
    "                message=ChatMessage(\n",
    "                    role=MessageRole.ASSISTANT,\n",
    "                    content=\"We need to find answers to the following questions:\\n\"\n",
    "                    + \"\\n\".join(res.research_questions),\n",
    "                )\n",
    "            )\n",
    "            for question in res.research_questions:\n",
    "                question_id = str(uuid.uuid4())\n",
    "                ctx.write_event_to_stream(\n",
    "                    DataEvent(\n",
    "                        type=\"deep_research_event\",\n",
    "                        data={\n",
    "                            \"event\": \"answer\",\n",
    "                            \"state\": \"pending\",\n",
    "                            \"id\": question_id,\n",
    "                            \"question\": question,\n",
    "                            \"answer\": None,\n",
    "                        },\n",
    "                    )\n",
    "                )\n",
    "                ctx.send_event(\n",
    "                    ResearchEvent(\n",
    "                        question_id=question_id,\n",
    "                        question=question,\n",
    "                        context_nodes=self.context_nodes,\n",
    "                    )\n",
    "                )\n",
    "        ctx.write_event_to_stream(\n",
    "            DataEvent(\n",
    "                type=\"deep_research_event\",\n",
    "                data={\n",
    "                    \"event\": \"analyze\",\n",
    "                    \"state\": \"done\",\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return None\n",
    "\n",
    "    @step(num_workers=2)\n",
    "    async def answer(self, ctx: Context, ev: ResearchEvent) -> CollectAnswersEvent:\n",
    "        \"\"\"\n",
    "        Answer the question\n",
    "        \"\"\"\n",
    "        ctx.write_event_to_stream(\n",
    "            DataEvent(\n",
    "                type=\"deep_research_event\",\n",
    "                data={\n",
    "                    \"event\": \"answer\",\n",
    "                    \"state\": \"inprogress\",\n",
    "                    \"id\": ev.question_id,\n",
    "                    \"question\": ev.question,\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "        try:\n",
    "            answer = await research(\n",
    "                context_nodes=ev.context_nodes,\n",
    "                question=ev.question,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error answering question {ev.question}: {e}\")\n",
    "            answer = f\"Got error when answering the question: {ev.question}\"\n",
    "        ctx.write_event_to_stream(\n",
    "            DataEvent(\n",
    "                type=\"deep_research_event\",\n",
    "                data={\n",
    "                    \"event\": \"answer\",\n",
    "                    \"state\": \"done\",\n",
    "                    \"id\": ev.question_id,\n",
    "                    \"question\": ev.question,\n",
    "                    \"answer\": answer,\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return CollectAnswersEvent(\n",
    "            question_id=ev.question_id,\n",
    "            question=ev.question,\n",
    "            answer=answer,\n",
    "        )\n",
    "\n",
    "    @step\n",
    "    async def collect_answers(\n",
    "        self, ctx: Context, ev: CollectAnswersEvent\n",
    "    ) -> PlanResearchEvent:\n",
    "        \"\"\"\n",
    "        Collect answers to all questions\n",
    "        \"\"\"\n",
    "        num_questions = await ctx.get(\"waiting_questions\")\n",
    "        results = ctx.collect_events(\n",
    "            ev,\n",
    "            expected=[CollectAnswersEvent] * num_questions,\n",
    "        )\n",
    "        if results is None:\n",
    "            return None\n",
    "        for result in results:\n",
    "            self.memory.put(\n",
    "                message=ChatMessage(\n",
    "                    role=MessageRole.ASSISTANT,\n",
    "                    content=f\"<Question>{result.question}</Question>\\n<Answer>{result.answer}</Answer>\",\n",
    "                )\n",
    "            )\n",
    "        await ctx.set(\"waiting_questions\", 0)\n",
    "        self.memory.put(\n",
    "            message=ChatMessage(\n",
    "                role=MessageRole.ASSISTANT,\n",
    "                content=\"Researched all the questions. Now, i need to analyze if it's ready to write a report or need to research more.\",\n",
    "            )\n",
    "        )\n",
    "        return PlanResearchEvent()\n",
    "\n",
    "    @step\n",
    "    async def report(self, ctx: Context, ev: ReportEvent) -> StopEvent:\n",
    "        \"\"\"\n",
    "        Report the answers\n",
    "        \"\"\"\n",
    "        res = await write_report(\n",
    "            memory=self.memory,\n",
    "            user_request=self.user_request,\n",
    "            stream=self.stream,\n",
    "        )\n",
    "        return StopEvent(\n",
    "            result=res,\n",
    "        )\n",
    "\n",
    "\n",
    "class AnalysisDecision(BaseModel):\n",
    "    decision: Literal[\"research\", \"write\", \"cancel\"] = Field(\n",
    "        description=\"Whether to continue research, write a report, or cancel the research after several retries\"\n",
    "    )\n",
    "    research_questions: Optional[List[str]] = Field(\n",
    "        description=\"\"\"\n",
    "        If the decision is to research, provide a list of questions to research that related to the user request.\n",
    "        Maximum 3 questions. Set to null or empty if writing a report or cancel the research.\n",
    "        \"\"\",\n",
    "        default_factory=list,\n",
    "    )\n",
    "    cancel_reason: Optional[str] = Field(\n",
    "        description=\"The reason for cancellation if the decision is to cancel research.\",\n",
    "        default=None,\n",
    "    )\n",
    "\n",
    "\n",
    "async def plan_research(\n",
    "    memory: SimpleComposableMemory,\n",
    "    context_nodes: List[Node],\n",
    "    user_request: str,\n",
    "    total_questions: int,\n",
    ") -> AnalysisDecision:\n",
    "    analyze_prompt = \"\"\"\n",
    "      You are a professor who is guiding a researcher to research a specific request/problem.\n",
    "      Your task is to decide on a research plan for the researcher.\n",
    "\n",
    "      The possible actions are:\n",
    "      + Provide a list of questions for the researcher to investigate, with the purpose of clarifying the request.\n",
    "      + Write a report if the researcher has already gathered enough research on the topic and can resolve the initial request.\n",
    "      + Cancel the research if most of the answers from researchers indicate there is insufficient information to research the request. Do not attempt more than 3 research iterations or too many questions.\n",
    "\n",
    "      The workflow should be:\n",
    "      + Always begin by providing some initial questions for the researcher to investigate.\n",
    "      + Analyze the provided answers against the initial topic/request. If the answers are insufficient to resolve the initial request, provide additional questions for the researcher to investigate.\n",
    "      + If the answers are sufficient to resolve the initial request, instruct the researcher to write a report.\n",
    "\n",
    "      Here are the context: \n",
    "      <Collected information>\n",
    "      {context_str}\n",
    "      </Collected information>\n",
    "\n",
    "      <Conversation context>\n",
    "      {conversation_context}\n",
    "      </Conversation context>\n",
    "\n",
    "      {enhanced_prompt}\n",
    "\n",
    "      Now, provide your decision in the required format for this user request:\n",
    "      <User request>\n",
    "      {user_request}\n",
    "      </User request>\n",
    "      \"\"\"\n",
    "    # Manually craft the prompt to avoid LLM hallucination\n",
    "    enhanced_prompt = \"\"\n",
    "    if total_questions == 0:\n",
    "        # Avoid writing a report without any research context\n",
    "        enhanced_prompt = \"\"\"\n",
    "        \n",
    "        The student has no questions to research. Let start by asking some questions.\n",
    "        \"\"\"\n",
    "    elif total_questions > 6:\n",
    "        # Avoid asking too many questions (when the data is not ready for writing a report)\n",
    "        enhanced_prompt = f\"\"\"\n",
    "\n",
    "        The student has researched {total_questions} questions. Should cancel the research if the context is not enough to write a report.\n",
    "        \"\"\"\n",
    "\n",
    "    conversation_context = \"\\n\".join(\n",
    "        [f\"{message.role}: {message.content}\" for message in memory.get_all()]\n",
    "    )\n",
    "    context_str = \"\\n\".join(\n",
    "        [node.get_content(metadata_mode=MetadataMode.LLM) for node in context_nodes]\n",
    "    )\n",
    "    res = await Settings.llm.astructured_predict(\n",
    "        output_cls=AnalysisDecision,\n",
    "        prompt=PromptTemplate(template=analyze_prompt),\n",
    "        user_request=user_request,\n",
    "        context_str=context_str,\n",
    "        conversation_context=conversation_context,\n",
    "        enhanced_prompt=enhanced_prompt,\n",
    "    )\n",
    "    return res\n",
    "\n",
    "\n",
    "async def research(\n",
    "    question: str,\n",
    "    context_nodes: List[NodeWithScore],\n",
    ") -> str:\n",
    "    prompt = \"\"\"\n",
    "    You are a researcher who is in the process of answering the question.\n",
    "    The purpose is to answer the question based on the collected information, without using prior knowledge or making up any new information.\n",
    "    Always add citations to the sentence/point/paragraph using the id of the provided content.\n",
    "    The citation should follow this format: [citation:id] where id is the id of the content.\n",
    "    \n",
    "    E.g:\n",
    "    If we have a context like this:\n",
    "    <Citation id='abc-xyz'>\n",
    "    Baby llama is called cria\n",
    "    </Citation id='abc-xyz'>\n",
    "\n",
    "    And your answer uses the content, then the citation should be:\n",
    "    - Baby llama is called cria [citation:abc-xyz]\n",
    "\n",
    "    Here is the provided context for the question:\n",
    "    <Collected information>\n",
    "    {context_str}\n",
    "    </Collected information>`\n",
    "\n",
    "    No prior knowledge, just use the provided context to answer the question: {question}\n",
    "    \"\"\"\n",
    "    context_str = \"\\n\".join(\n",
    "        [_get_text_node_content_for_citation(node) for node in context_nodes]\n",
    "    )\n",
    "    res = await Settings.llm.acomplete(\n",
    "        prompt=prompt.format(question=question, context_str=context_str),\n",
    "    )\n",
    "    return res.text\n",
    "\n",
    "\n",
    "async def write_report(\n",
    "    memory: SimpleComposableMemory,\n",
    "    user_request: str,\n",
    "    stream: bool = False,\n",
    ") -> CompletionResponse | CompletionResponseAsyncGen:\n",
    "    report_prompt = \"\"\"\n",
    "    You are a researcher writing a report based on a user request and the research context.\n",
    "    You have researched various perspectives related to the user request.\n",
    "    The report should provide a comprehensive outline covering all important points from the researched perspectives.\n",
    "    Create a well-structured outline for the research report that covers all the answers.\n",
    "\n",
    "    # IMPORTANT when writing in markdown format:\n",
    "    + Use tables or figures where appropriate to enhance presentation.\n",
    "    + Preserve all citation syntax (the `[citation:id]()` parts in the provided context). Keep these citations in the final report - no separate reference section is needed.\n",
    "    + Do not add links, a table of contents, or a references section to the report.\n",
    "\n",
    "    <User request>\n",
    "    {user_request}\n",
    "    </User request>\n",
    "\n",
    "    <Research context>\n",
    "    {research_context}\n",
    "    </Research context>\n",
    "\n",
    "    Now, write a report addressing the user request based on the research provided following the format and guidelines above.\n",
    "    \"\"\"\n",
    "    research_context = \"\\n\".join(\n",
    "        [f\"{message.role}: {message.content}\" for message in memory.get_all()]\n",
    "    )\n",
    "\n",
    "    llm_complete_func = (\n",
    "        Settings.llm.astream_complete if stream else Settings.llm.acomplete\n",
    "    )\n",
    "\n",
    "    res = await llm_complete_func(\n",
    "        prompt=report_prompt.format(\n",
    "            user_request=user_request,\n",
    "            research_context=research_context,\n",
    "        ),\n",
    "    )\n",
    "    return res\n",
    "\n",
    "\n",
    "def _get_text_node_content_for_citation(node: NodeWithScore) -> str:\n",
    "    \"\"\"\n",
    "    Construct node content for LLM with citation flag.\n",
    "    \"\"\"\n",
    "    node_id = node.node.node_id\n",
    "    content = f\"<Citation id='{node_id}'>\\n{node.get_content(metadata_mode=MetadataMode.LLM)}</Citation id='{node_id}'>\"\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "26df004e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 55.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval done\n",
      "type='deep_research_event' data=DeepResearchEventData(event='retrieve', state='inprogress', id=None, question=None, answer=None)\n",
      "type='deep_research_event' data=DeepResearchEventData(event='retrieve', state='done', id=None, question=None, answer=None)\n",
      "Analyzing the retrieved information\n",
      "type='deep_research_event' data=DeepResearchEventData(event='analyze', state='inprogress', id=None, question=None, answer=None)\n",
      "type='deep_research_event' data=DeepResearchEventData(event='answer', state='pending', id='1b4a85ee-5bec-438c-a8a0-33c1be93ae3f', question='What were the key biological parameters studied in relation to Spirinchus starksi?', answer=None)\n",
      "type='deep_research_event' data=DeepResearchEventData(event='answer', state='pending', id='765bfe80-7b83-44f9-a437-e8cbd044103c', question='How was Traditional Ecological Knowledge (TEK) incorporated into the study of Spirinchus starksi?', answer=None)\n",
      "type='deep_research_event' data=DeepResearchEventData(event='answer', state='pending', id='6a4465c4-2703-4730-9fa9-748fc009cef1', question='What were the main conclusions regarding the status of Spirinchus starksi in Northern California based on the study?', answer=None)\n",
      "type='deep_research_event' data=DeepResearchEventData(event='analyze', state='done', id=None, question=None, answer=None)\n",
      "type='deep_research_event' data=DeepResearchEventData(event='answer', state='inprogress', id='1b4a85ee-5bec-438c-a8a0-33c1be93ae3f', question='What were the key biological parameters studied in relation to Spirinchus starksi?', answer=None)\n",
      "type='deep_research_event' data=DeepResearchEventData(event='answer', state='inprogress', id='765bfe80-7b83-44f9-a437-e8cbd044103c', question='How was Traditional Ecological Knowledge (TEK) incorporated into the study of Spirinchus starksi?', answer=None)\n",
      "type='deep_research_event' data=DeepResearchEventData(event='answer', state='done', id='1b4a85ee-5bec-438c-a8a0-33c1be93ae3f', question='What were the key biological parameters studied in relation to Spirinchus starksi?', answer='The study of *Spirinchus starksi* (night smelt) in Humboldt and Del Norte counties involved comparing abundance, length, weight, age, sex ratio, and timing of reproduction of the night smelt population [citation:98c16ca4]. Fish samples were measured for total length (TL, mm), weighted (g), and sexed [citation:8d4a5841]. Otoliths were also taken for future analysis [citation:8d4a5841].\\n')\n",
      "type='deep_research_event' data=DeepResearchEventData(event='answer', state='inprogress', id='6a4465c4-2703-4730-9fa9-748fc009cef1', question='What were the main conclusions regarding the status of Spirinchus starksi in Northern California based on the study?', answer=None)\n",
      "type='deep_research_event' data=DeepResearchEventData(event='answer', state='done', id='765bfe80-7b83-44f9-a437-e8cbd044103c', question='How was Traditional Ecological Knowledge (TEK) incorporated into the study of Spirinchus starksi?', answer='Traditional Ecological Knowledge (TEK) was merged with biological parameters to study night smelt [citation:b1eb1405-9fbf-4010-9d14-65ba96be1f42]. This approach provided knowledge of the Indigenous role of smelt as a dietary and subsistence species of importance, as well as a general understanding of the biology of spawning individuals and environmental conditions [citation:b1eb1405-9fbf-4010-9d14-65ba96be1f42]. The study used TEK to explore the significance of night smelt for Tribal nations [citation:98c16ca4-3464-4f10-9aa2-467bea332f20].\\n')\n",
      "type='deep_research_event' data=DeepResearchEventData(event='answer', state='done', id='6a4465c4-2703-4730-9fa9-748fc009cef1', question='What were the main conclusions regarding the status of Spirinchus starksi in Northern California based on the study?', answer='The study aimed to understand the status of the night smelt (Spirinchus starksi) population in Humboldt and Del Norte counties [citation:98c16ca4-3464-4f10-9aa2-467bea332f20]. The study compared the abundance, length, weight, age, sex ratio, and timing of reproduction of the night smelt population in Humboldt and Del Norte counties during 2014 and 2021 [citation:98c16ca4-3464-4f10-9aa2-467bea332f20]. It also quantified their larvae in the nearshore ocean since 2007, analyzed commercial catches in Humboldt County over the last 20 years, and used traditional and local ecological knowledge to explore the significance of night smelt for the Tribal nations [citation:98c16ca4-3464-4f10-9aa2-467bea332f20]. By merging biological parameters and traditional ecological knowledge, the study gained knowledge of the Indigenous role of smelt and a general understanding of the biology of spawning individuals and environmental conditions in 2021 [citation:b1eb1405-9fbf-4010-9d14-65ba96be1f42].\\n')\n",
      "Analyzing the retrieved information\n",
      "type='deep_research_event' data=DeepResearchEventData(event='analyze', state='inprogress', id=None, question=None, answer=None)\n",
      "type='deep_research_event' data=DeepResearchEventData(event='analyze', state='done', id=None, question=None, answer=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<async_generator object llm_completion_callback.<locals>.wrap.<locals>.wrapped_async_llm_predict.<locals>.wrapped_gen at 0x7fa9346c8640>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Postgres credentials from connection string\n",
    "pg_url = urlparse(os.getenv(\"PG_CONN_STR\"))\n",
    "host = pg_url.hostname\n",
    "port = pg_url.port\n",
    "database = pg_url.path[1:]\n",
    "user = pg_url.username\n",
    "password = pg_url.password\n",
    "\n",
    "# Vector store to store chunks + embeddings in\n",
    "\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    host=host,\n",
    "    port=port,\n",
    "    database=database,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    table_name=\"llamaindex_docs\",\n",
    "    schema_name=\"public\",\n",
    "    hybrid_search=True,\n",
    "    embed_dim=768,\n",
    "    hnsw_kwargs={\n",
    "        \"hnsw_m\": 16,\n",
    "        \"hnsw_ef_construction\": 64,\n",
    "        \"hnsw_ef_search\": 40,\n",
    "        \"hnsw_dist_method\": \"vector_cosine_ops\",\n",
    "    },\n",
    ")\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store,\n",
    "    embed_model=HuggingFaceEmbedding(\n",
    "        model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# text_retriever = index.as_retriever(\n",
    "#     vector_store_query_mode=\"sparse\", similarity_top_k=10\n",
    "# )\n",
    "\n",
    "\n",
    "w = DeepResearchWorkflow(index=index, timeout=120)\n",
    "\n",
    "handler = w.run(user_msg=\"Can you summarize the key findings of ‚ÄúUSING BIOLOGICAL PARAMETERS AND TRADITIONAL ECOLOGICAL KNOWLEDGE TO STUDY THE STATUS OF Spirinchus starksi (NIGHT SMELT) IN NORTHERN CALIFORNIA‚Äù by Z Zenobia?\")\n",
    "async for ev in w.stream_events():\n",
    "    print(ev) \n",
    "\n",
    "await handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "990d3c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<async_generator object llm_completion_callback.<locals>.wrap.<locals>.wrapped_async_llm_predict.<locals>.wrapped_gen at 0x7fa971233440>\n"
     ]
    }
   ],
   "source": [
    "print(str(handler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da868d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
